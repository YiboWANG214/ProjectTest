{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_response(json_file, csv_file, json_content, csv_content, isGPT=False) -> None:\n",
    "    json_file.write(json.dumps(json_content, indent=4))  # save immediately\n",
    "    json_file.write(\",\")\n",
    "    json_file.write(\"\\n\")\n",
    "\n",
    "    if isGPT:\n",
    "        csv_file.writerow(csv_content)\n",
    "    else:\n",
    "        print(\"isGPT error\")\n",
    "\n",
    "def save_generated_code(id: str, code: str, output_folder: str, isGPT3=False) -> None:\n",
    "    # get the original sample filename and extension (this makes the generation logic generic to any language)\n",
    "    filename = id.split(\"/\")[-1]\n",
    "    # print(filename)\n",
    "\n",
    "    # create the output folder if needed\n",
    "    if not os.path.exists(output_folder): os.makedirs(output_folder)\n",
    "\n",
    "    with open(os.path.join(output_folder, filename), \"w\") as gen_file:\n",
    "        if isGPT3:\n",
    "            gen_file.write(code)\n",
    "        else:\n",
    "            # gen_file.write(prompt[\"test_prompt\"] + \"\\n\" + response['choices'][0][\"text\"])\n",
    "            print(\"isGPT3 error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProjectTest_Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_file = \"./ProjectTest/Python/original_prompt.json\"\n",
    "# csv_file = \"./ProjectTest/Python/original_prompt.csv\"\n",
    "# output_folder = \"./ProjectTest/Python/main\"\n",
    "\n",
    "\n",
    "# dataset = []\n",
    "# folder_path = './dataset/Python/'\n",
    "\n",
    "# def nested_dir(name, dir_path):\n",
    "#     original_code = \"\"\n",
    "#     num_file = 0\n",
    "#     num_line = 0\n",
    "#     num_function = 0\n",
    "#     num_class = 0\n",
    "#     for item in os.listdir(dir_path):\n",
    "#         path = os.path.join(dir_path, item)\n",
    "#         if os.path.isdir(path):\n",
    "#             cur_name = name + \"/\" + item\n",
    "#             cur_code, cur_num_file, cur_num_line, cur_num_func, cur_num_class = nested_dir(cur_name, path)\n",
    "#             original_code += cur_code\n",
    "#             num_file += cur_num_file\n",
    "#             num_line += cur_num_line\n",
    "#             num_function += cur_num_func\n",
    "#             num_class += cur_num_class\n",
    "#         else:\n",
    "#             if item.split('.')[-1] != \"py\":\n",
    "#                 continue\n",
    "#             if os.path.isfile(path):\n",
    "#                 with open(path, 'r') as file:\n",
    "#                     lines = file.readlines()\n",
    "#                 original_code += f\"'''\\n{name}/{item}\\n'''\\n\"\n",
    "#                 for line in lines:\n",
    "#                     if \"if __name__ ==\" in line:\n",
    "#                         break\n",
    "#                     original_code += line\n",
    "#                     num_function += line.count(\"def \")\n",
    "#                     num_class += line.count(\"class \")\n",
    "#                 original_code += \"\\n\\n\"\n",
    "#                 num_file += 1\n",
    "#                 num_line += len(lines)\n",
    "#     return original_code, num_file, num_line, num_function, num_class\n",
    "\n",
    "# i = 0\n",
    "# for item in os.listdir(folder_path):\n",
    "#     original_code = \"\"\n",
    "#     num_file = 0\n",
    "#     num_line = 0\n",
    "#     num_function = 0\n",
    "#     num_class = 0\n",
    "#     item_path = os.path.join(folder_path, item)\n",
    "#     sample = dict()\n",
    "#     class_name = item\n",
    "#     if os.path.isdir(item_path):\n",
    "#         # Iterate through each file in the folder\n",
    "#         for filename in os.listdir(item_path):\n",
    "#             file_path = os.path.join(item_path, filename)\n",
    "#             if os.path.isdir(file_path):\n",
    "#                 cur_name = item_path.split('/')[-1] + \"/\" + filename\n",
    "#                 cur_code, cur_num_file, cur_num_line, cur_num_func, cur_num_class = nested_dir(cur_name, file_path)\n",
    "#                 original_code += cur_code\n",
    "#                 num_file += cur_num_file\n",
    "#                 num_line += cur_num_line\n",
    "#                 num_function += cur_num_func\n",
    "#                 num_class += cur_num_class\n",
    "#             else:\n",
    "#                 if filename.split('.')[-1] != \"py\":\n",
    "#                     continue\n",
    "#                 if os.path.isfile(file_path):\n",
    "#                     # print(filename)\n",
    "#                     with open(file_path, 'r') as file:\n",
    "#                         lines = file.readlines()\n",
    "#                     original_code += f\"'''\\n{item_path.split('/')[-1]}/{filename}\\n'''\\n\"\n",
    "#                     for line in lines:\n",
    "#                         if \"if __name__ ==\" in line:\n",
    "#                             break\n",
    "#                         original_code += line\n",
    "#                         num_function += line.count(\"def \")\n",
    "#                         num_class += line.count(\"class \")\n",
    "#                     original_code += \"\\n\\n\"\n",
    "#                     num_file += 1\n",
    "#                     num_line += len(lines)\n",
    "    \n",
    "#         sample[\"solution_code\"] = original_code\n",
    "#         sample[\"class_name\"] = class_name\n",
    "#         sample[\"task_id\"] = f\"id_{i}\"\n",
    "#         sample[\"num_file\"] = num_file\n",
    "#         sample[\"num_line\"] = num_line\n",
    "#         sample[\"num_function\"] = num_function\n",
    "#         sample[\"num_class\"] = num_class\n",
    "#         i += 1\n",
    "#         dataset.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# with open(response_file, \"w\") as json_file, open(csv_file, \"w\") as csv_out:\n",
    "#     csv_file = csv.writer(\n",
    "#         csv_out, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL\n",
    "#     )\n",
    "#     csv_file.writerow(\n",
    "#         [\n",
    "#             \"id\",\n",
    "#             \"classname\",\n",
    "#             \"method_signature\",\n",
    "#             \"package\",\n",
    "#             \"suffix\",\n",
    "#             \"num_file\",\n",
    "#             \"num_line\",\n",
    "#             \"num_function\",\n",
    "#             \"num_class\",\n",
    "#         ]\n",
    "#     )\n",
    "#     json_file.write(\"[\\n\")\n",
    "    \n",
    "#     print(len(dataset))\n",
    "#     for sample in dataset:\n",
    "#         # print(sample)\n",
    "#         numberTests = \"enough\"\n",
    "#         original_code = sample[\"solution_code\"]\n",
    "#         package = \"original\"\n",
    "#         classname = sample[\"class_name\"]\n",
    "#         id = \"./Proj/\"+classname+\".py\"\n",
    "#         method_signature = classname\n",
    "#         test_prompt = f\"Please generate enough unit test cases for each python file in the {method_signature} project. Ensure that the import path is correct, depending on whether the project is structured as a package. Make sure the tests can successfully compile. Make sure the tests have correct results. Try to achieve the highest coverage rate. \"+\"\\n\\n\"\n",
    "#         suffix = \"\"\n",
    "#         num_file = sample[\"num_file\"]\n",
    "#         num_line = sample[\"num_line\"]\n",
    "#         num_function = sample[\"num_function\"]\n",
    "#         num_class = sample[\"num_class\"]\n",
    "#         cur_sample = {\"numberTests\":numberTests,\n",
    "#                     \"original_code\":original_code,\n",
    "#                     \"package\":package,\n",
    "#                     \"classname\":classname,\n",
    "#                     \"id\":id,\n",
    "#                     \"test_prompt\":test_prompt,\n",
    "#                     \"method_signature\":method_signature,\n",
    "#                     \"suffix\":suffix}\n",
    "#         csv_content = [id, method_signature, classname, package, suffix, num_file, num_line, num_function, num_class]\n",
    "#         save_response(json_file, csv_file, cur_sample, csv_content, isGPT=True)\n",
    "#         save_generated_code(classname+\".py\", original_code, output_folder, isGPT3=True)\n",
    "#     json_file.write(\"]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProjectTest_Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_file = \"./ProjectTest/JAVA/original_prompt.json\"\n",
    "# csv_file = \"./ProjectTest/JAVA/original_prompt.csv\"\n",
    "# output_folder = \"./ProjectTest/JAVA/main\"\n",
    "\n",
    "\n",
    "# dataset = []\n",
    "# folder_path = './dataset/JAVA/'\n",
    "\n",
    "# def nested_dir(name, dir_path):\n",
    "#     original_code = \"\"\n",
    "#     num_file = 0\n",
    "#     num_line = 0\n",
    "#     num_function = 0\n",
    "#     num_class = 0\n",
    "#     for item in os.listdir(dir_path):\n",
    "#         path = os.path.join(dir_path, item)\n",
    "#         if os.path.isdir(path):\n",
    "#             cur_name = name + \"/\" + item\n",
    "#             cur_code, cur_num_file, cur_num_line, cur_num_func, cur_num_class = nested_dir(cur_name, path)\n",
    "#             original_code += cur_code\n",
    "#             num_file += cur_num_file\n",
    "#             num_line += cur_num_line\n",
    "#             num_function += cur_num_func\n",
    "#             num_class += cur_num_class\n",
    "#         else:\n",
    "#             if item.split('.')[-1] != \"java\":\n",
    "#                 continue\n",
    "#             if os.path.isfile(path):\n",
    "#                 with open(path, 'r') as file:\n",
    "#                     lines = file.readlines()\n",
    "#                 original_code += f\"// {name}/{item}\\n\\n\"\n",
    "#                 for line in lines:\n",
    "#                     original_code += line\n",
    "#                     num_function += line.count(\"def \")\n",
    "#                     num_class += line.count(\"class \")\n",
    "#                 original_code += \"\\n\\n\"\n",
    "#                 num_file += 1\n",
    "#                 num_line += len(lines)\n",
    "#     return original_code, num_file, num_line, num_function, num_class\n",
    "\n",
    "# i = 0\n",
    "# for item in os.listdir(folder_path):\n",
    "#     # if (item != \"stock3\") and (item != \"stock4\"):\n",
    "#     #     continue\n",
    "#     original_code = \"\"\n",
    "#     num_file = 0\n",
    "#     num_line = 0\n",
    "#     num_function = 0\n",
    "#     num_class = 0\n",
    "#     item_path = os.path.join(folder_path, item)\n",
    "#     sample = dict()\n",
    "#     class_name = item\n",
    "#     if os.path.isdir(item_path):\n",
    "#         # Iterate through each file in the folder\n",
    "#         for filename in os.listdir(item_path):\n",
    "#             file_path = os.path.join(item_path, filename)\n",
    "#             if os.path.isdir(file_path):\n",
    "#                 cur_name = item_path.split('/')[-1] + \"/\" + filename\n",
    "#                 cur_code, cur_num_file, cur_num_line, cur_num_func, cur_num_class = nested_dir(cur_name, file_path)\n",
    "#                 original_code += cur_code\n",
    "#                 num_file += cur_num_file\n",
    "#                 num_line += cur_num_line\n",
    "#                 num_function += cur_num_func\n",
    "#                 num_class += cur_num_class\n",
    "#             else:\n",
    "#                 if filename.split('.')[-1] != \"java\":\n",
    "#                     continue\n",
    "#                 if os.path.isfile(file_path):\n",
    "#                     # print(filename)\n",
    "#                     with open(file_path, 'r') as file:\n",
    "#                         lines = file.readlines()\n",
    "#                     original_code += f\"// {item_path.split('/')[-1]}/{filename}\\n\\n\"\n",
    "#                     for line in lines:\n",
    "#                         original_code += line\n",
    "#                         num_function += line.count(\"def \")\n",
    "#                         num_class += line.count(\"class \")\n",
    "#                     original_code += \"\\n\\n\"\n",
    "#                     num_file += 1\n",
    "#                     num_line += len(lines)\n",
    "\n",
    "#         sample[\"solution_code\"] = original_code\n",
    "#         sample[\"class_name\"] = class_name\n",
    "#         sample[\"task_id\"] = f\"id_{i}\"\n",
    "#         sample[\"num_file\"] = num_file\n",
    "#         sample[\"num_line\"] = num_line\n",
    "#         sample[\"num_function\"] = num_function\n",
    "#         sample[\"num_class\"] = num_class\n",
    "#         i += 1\n",
    "#         dataset.append(sample)\n",
    "#     # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "# with open(response_file, \"w\") as json_file, open(csv_file, \"w\") as csv_out:\n",
    "#     csv_file = csv.writer(\n",
    "#         csv_out, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL\n",
    "#     )\n",
    "#     csv_file.writerow(\n",
    "#         [\n",
    "#             \"id\",\n",
    "#             \"classname\",\n",
    "#             \"method_signature\",\n",
    "#             \"package\",\n",
    "#             \"suffix\",\n",
    "#             \"num_file\",\n",
    "#             \"num_line\",\n",
    "#             \"num_function\",\n",
    "#             \"num_class\",\n",
    "#         ]\n",
    "#     )\n",
    "#     json_file.write(\"[\\n\")\n",
    "    \n",
    "#     print(len(dataset))\n",
    "#     for sample in dataset:\n",
    "#         numberTests = \"enough\"\n",
    "#         original_code = sample[\"solution_code\"]\n",
    "#         package = \"original\"\n",
    "#         classname = sample[\"class_name\"]\n",
    "#         id = \"./ProjectTest/JAVA/\"+classname+\".java\"\n",
    "#         method_signature = classname\n",
    "#         test_prompt = \"Please generate enough unit test cases for each java file in the {method_signature} project. Ensure to use mock properly for unit tests. Make sure the tests can successfully compile. Make sure the tests have correct results. Try to achieve the highest coverage rate.\\n\"\n",
    "#         suffix = \"\"\n",
    "#         num_file = sample[\"num_file\"]\n",
    "#         num_line = sample[\"num_line\"]\n",
    "#         num_function = sample[\"num_function\"]\n",
    "#         num_class = sample[\"num_class\"]\n",
    "#         cur_sample = {\"numberTests\":numberTests,\n",
    "#                     \"original_code\":original_code,\n",
    "#                     \"package\":package,\n",
    "#                     \"classname\":classname,\n",
    "#                     \"id\":id,\n",
    "#                     \"test_prompt\":test_prompt,\n",
    "#                     \"method_signature\":method_signature,\n",
    "#                     \"suffix\":suffix}\n",
    "#         csv_content = [id, method_signature, classname, package, suffix, num_file, num_line, num_function, num_class]\n",
    "#         save_response(json_file, csv_file, cur_sample, csv_content, isGPT=True)\n",
    "#         save_generated_code(classname+\".java\", original_code, output_folder, isGPT3=True)\n",
    "#     json_file.write(\"]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProjectTest_JS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_file = \"./ProjectTest/JS/original_prompt.json\"\n",
    "# csv_file = \"./ProjectTest/JS/original_prompt.csv\"\n",
    "# output_folder = \"./ProjectTest/JS/main\"\n",
    "\n",
    "\n",
    "# dataset = []\n",
    "# folder_path = './dataset/JS/'\n",
    "\n",
    "# def nested_dir(name, dir_path):\n",
    "#     original_code = \"\"\n",
    "#     num_file = 0\n",
    "#     num_line = 0\n",
    "#     num_function = 0\n",
    "#     num_class = 0\n",
    "#     for item in os.listdir(dir_path):\n",
    "#         path = os.path.join(dir_path, item)\n",
    "#         if os.path.isdir(path):\n",
    "#             cur_name = name + \"/\" + item\n",
    "#             cur_code, cur_num_file, cur_num_line, cur_num_func, cur_num_class = nested_dir(cur_name, path)\n",
    "#             original_code += cur_code\n",
    "#             num_file += cur_num_file\n",
    "#             num_line += cur_num_line\n",
    "#             num_function += cur_num_func\n",
    "#             num_class += cur_num_class\n",
    "#         else:\n",
    "#             if item.split('.')[-1] != \"js\":\n",
    "#                 continue\n",
    "#             if os.path.isfile(path):\n",
    "#                 with open(path, 'r') as file:\n",
    "#                     lines = file.readlines()\n",
    "#                 original_code += f\"// {name}/{item}\\n\\n\"\n",
    "#                 for line in lines:\n",
    "#                     original_code += line\n",
    "#                     num_function += line.count(\"def \")\n",
    "#                     num_class += line.count(\"class \")\n",
    "#                 original_code += \"\\n\\n\"\n",
    "#                 num_file += 1\n",
    "#                 num_line += len(lines)\n",
    "#     return original_code, num_file, num_line, num_function, num_class\n",
    "\n",
    "# i = 0\n",
    "# for item in os.listdir(folder_path):\n",
    "#     original_code = \"\"\n",
    "#     num_file = 0\n",
    "#     num_line = 0\n",
    "#     num_function = 0\n",
    "#     num_class = 0\n",
    "#     item_path = os.path.join(folder_path, item)\n",
    "#     sample = dict()\n",
    "#     class_name = item\n",
    "#     if os.path.isdir(item_path):\n",
    "#         # Iterate through each file in the folder\n",
    "#         for filename in os.listdir(item_path):\n",
    "#             file_path = os.path.join(item_path, filename)\n",
    "#             if os.path.isdir(file_path):\n",
    "#                 cur_name = item_path.split('/')[-1] + \"/\" + filename\n",
    "#                 cur_code, cur_num_file, cur_num_line, cur_num_func, cur_num_class = nested_dir(cur_name, file_path)\n",
    "#                 original_code += cur_code\n",
    "#                 num_file += cur_num_file\n",
    "#                 num_line += cur_num_line\n",
    "#                 num_function += cur_num_func\n",
    "#                 num_class += cur_num_class\n",
    "#             else:\n",
    "#                 if filename.split('.')[-1] != \"js\":\n",
    "#                     continue\n",
    "#                 if os.path.isfile(file_path):\n",
    "#                     # print(filename)\n",
    "#                     with open(file_path, 'r') as file:\n",
    "#                         lines = file.readlines()\n",
    "#                     original_code += f\"// {item_path.split('/')[-1]}/{filename}\\n\\n\"\n",
    "#                     for line in lines:\n",
    "#                         original_code += line\n",
    "#                         num_function += line.count(\"def \")\n",
    "#                         num_class += line.count(\"class \")\n",
    "#                     original_code += \"\\n\\n\"\n",
    "#                     num_file += 1\n",
    "#                     num_line += len(lines)\n",
    "\n",
    "#         sample[\"solution_code\"] = original_code\n",
    "#         sample[\"class_name\"] = class_name\n",
    "#         sample[\"task_id\"] = f\"id_{i}\"\n",
    "#         sample[\"num_file\"] = num_file\n",
    "#         sample[\"num_line\"] = num_line\n",
    "#         sample[\"num_function\"] = num_function\n",
    "#         sample[\"num_class\"] = num_class\n",
    "#         i += 1\n",
    "#         dataset.append(sample)\n",
    "#     # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# with open(response_file, \"w\") as json_file, open(csv_file, \"w\") as csv_out:\n",
    "#     csv_file = csv.writer(\n",
    "#         csv_out, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL\n",
    "#     )\n",
    "#     csv_file.writerow(\n",
    "#         [\n",
    "#             \"id\",\n",
    "#             \"classname\",\n",
    "#             \"method_signature\",\n",
    "#             \"package\",\n",
    "#             \"suffix\",\n",
    "#             \"num_file\",\n",
    "#             \"num_line\",\n",
    "#             \"num_function\",\n",
    "#             \"num_class\",\n",
    "#         ]\n",
    "#     )\n",
    "#     json_file.write(\"[\\n\")\n",
    "    \n",
    "#     print(len(dataset))\n",
    "#     for sample in dataset:\n",
    "#         # print(sample)\n",
    "#         numberTests = \"enough\"\n",
    "#         original_code = sample[\"solution_code\"]\n",
    "#         package = \"original\"\n",
    "#         classname = sample[\"class_name\"]\n",
    "#         id = \"./Pro/\"+classname+\".js\"\n",
    "#         method_signature = classname\n",
    "#         test_prompt = \"Please generate enough unit test cases for every javascript file in {method_signature} project. Do not miss any file. Make sure the tests can successfully compile. Make sure the tests have correct results. Try to achieve the highest coverage rate.\\n\"\n",
    "#         suffix = \"\"\n",
    "#         num_file = sample[\"num_file\"]\n",
    "#         num_line = sample[\"num_line\"]\n",
    "#         num_function = sample[\"num_function\"]\n",
    "#         num_class = sample[\"num_class\"]\n",
    "#         cur_sample = {\"numberTests\":numberTests,\n",
    "#                     \"original_code\":original_code,\n",
    "#                     \"package\":package,\n",
    "#                     \"classname\":classname,\n",
    "#                     \"id\":id,\n",
    "#                     \"test_prompt\":test_prompt,\n",
    "#                     \"method_signature\":method_signature,\n",
    "#                     \"suffix\":suffix}\n",
    "#         csv_content = [id, method_signature, classname, package, suffix, num_file, num_line, num_function, num_class]\n",
    "#         save_response(json_file, csv_file, cur_sample, csv_content, isGPT=True)\n",
    "#         save_generated_code(classname+\".js\", original_code, output_folder, isGPT3=True)\n",
    "#     json_file.write(\"]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests fixing (python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def get_classname(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Gets the name of the CUT from the test prompt.\n",
    "    @param code: the test prompt or the original code (it assumes it starts with `// classname.java`)\n",
    "    @return: the classname of the CUT or the unit test to be generated\n",
    "    \"\"\"\n",
    "    return code.split(\"\\n\")[0][2:-8].strip()\n",
    "\n",
    "def save_generated_code(filename: str, code: str, output_folder: str, isGPT3=False) -> None:\n",
    "    # create the output folder if needed\n",
    "    if not os.path.exists(output_folder): os.makedirs(output_folder)\n",
    "\n",
    "    with open(os.path.join(output_folder, filename), \"w\") as gen_file:\n",
    "        if isGPT3:\n",
    "            gen_file.write(code)\n",
    "        else:\n",
    "            # gen_file.write(prompt[\"test_prompt\"] + \"\\n\" + response['choices'][0][\"text\"])\n",
    "            print(\"isGPT3 error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fix1(code):\n",
    "    \"\"\"\n",
    "    delete \"```python\" at the begining, and \"```\" at the end ==> H2\n",
    "    \"\"\"\n",
    "    applied_heuristic = False\n",
    "    pattern = r\"[\\S\\s.]*?\\`\\`\\`python([\\S\\s.]*?)\\`\\`\\`[\\S\\s.]*?\"\n",
    "    good_code = re.findall(pattern, code, re.DOTALL)\n",
    "    if len(good_code) > 0:\n",
    "        # print(\"This is length: \" , len(good_code))\n",
    "        code = good_code[0]\n",
    "        for i in range(1, len(good_code)):\n",
    "            code += good_code[i]\n",
    "        applied_heuristic = True\n",
    "    if code.count(\"if __name__ == '__main__':\\n    unittest.main()\") > 1:\n",
    "        code = code.split(\"if __name__ == '__main__':\\n    unittest.main()\")\n",
    "        code = \"\\n\".join(code) + \"\\nif __name__ == '__main__':\\n    unittest.main()\"\n",
    "    return code, applied_heuristic\n",
    "\n",
    "def fix2(code, test_classname, function_file):\n",
    "    \"\"\"\n",
    "    replaces the package name with the function file name ==> H4\n",
    "    adds the package name if it is missing (or remove it, if it is not needed) ==> H5\n",
    "    \"\"\"\n",
    "    applied_heuristic_h4, applied_heuristic_h5 = False, False\n",
    "\n",
    "    # search only in the beginning of the file (before the test class)\n",
    "    if not re.search(f\"import {test_classname}\", code, re.IGNORECASE):\n",
    "        print(function_file)\n",
    "        return code, applied_heuristic_h4, applied_heuristic_h5\n",
    "    m = re.search(f\"from {test_classname} \", code[:code.index(f\"import {test_classname}\")], re.IGNORECASE)\n",
    "    # print(test_classname, code[:code.index(f\"import {test_classname}\")])\n",
    "    # print(m)\n",
    "    \n",
    "    missing = True\n",
    "    if m:\n",
    "        missing = False\n",
    "        code = code[:m.start()] + f\"from {function_file} \" + code[m.end():]\n",
    "    \n",
    "    # test should be in a package, but package declaration is missing\n",
    "    # thus, apply H5 here\n",
    "    # print(code[:m.start()])\n",
    "    # print(test_classname, missing)\n",
    "    if test_classname and missing:\n",
    "        code = f\"from {function_file} import {test_classname}\\n\" + code\n",
    "        applied_heuristic_h5 = True\n",
    "    # if not test_classname and not missing:\n",
    "    #     # remove the package declaration\n",
    "    #     code = code[:m.start()] + code[m.end():]\n",
    "    #     applied_heuristic_h5 = True\n",
    "    return code, applied_heuristic_h4, applied_heuristic_h5\n",
    "\n",
    "def fix3(code):\n",
    "    \"\"\"\n",
    "    delete \"```\" at the begining, and \"```\" at the end\n",
    "    \"\"\"\n",
    "    applied_heuristic = False\n",
    "    pattern = r\"[\\S\\s.]*?\\`\\`\\`([\\S\\s.]*?)\\`\\`\\`[\\S\\s.]*?\"\n",
    "    good_code = re.findall(pattern, code, re.DOTALL)\n",
    "    if len(good_code) > 0:\n",
    "        # print(\"This is length: \" , len(good_code))\n",
    "        code = good_code[0]\n",
    "        for i in range(1, len(good_code)):\n",
    "            code += good_code[i]\n",
    "        applied_heuristic = True\n",
    "    return code, applied_heuristic\n",
    "\n",
    "\n",
    "def fix4(code):\n",
    "    \"\"\"\n",
    "    delete text after \"unittest.main()\"\n",
    "    \"\"\"\n",
    "    applied_heuristic = False\n",
    "    # Find the position of `unittest.main()`\n",
    "    position = code.find('unittest.main()')\n",
    "\n",
    "    # Check if `unittest.main()` was found\n",
    "    if position != -1:\n",
    "        # Include the length of 'unittest.main()' to capture the whole line\n",
    "        code = code[:position + len('unittest.main()')]\n",
    "    \n",
    "    return code, applied_heuristic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProjectTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPT3.5 fix1\n",
    "# # CodeLlama fix3 + formatter\n",
    "\n",
    "# model = \"O1\"\n",
    "# fix_folder = [f\"./generated_tests/{model}_Data/ProjectTestPy_output/original_fix\"]\n",
    "# output_folder = [f\"./generated_tests/{model}_Data/ProjectTestPy_output/original_output_-1.json\"]\n",
    "# models = [model]\n",
    "# applied_heuristics = [False for _ in range(0, 7)]\n",
    "\n",
    "# for i in range(len(models)):\n",
    "#     model = models[i]\n",
    "#     for dataset in [\"ProjectTest\"]:\n",
    "#         tests_output = json.load(open(output_folder[i]))\n",
    "#         for test_dict in tests_output:\n",
    "#             if (model == \"GPT3.5\") or (model == \"GPT4\") or (model == \"O1\"):\n",
    "#                 old_test = test_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "#                 # old_test = test_dict[\"generated_text\"]\n",
    "#                 function_file = test_dict[\"prompt_id\"].split('/')[-1].split('.')[0]\n",
    "#                 test_classname = get_classname(test_dict[\"test_prompt\"].strip())\n",
    "#                 # \"```python\" and \"```\"\n",
    "#                 old_test, applied_heuristics[1] = fix1(old_test)\n",
    "#             elif model == \"Gemini\" or model == \"Claude\":\n",
    "#                 old_test = test_dict[\"generated_text\"]\n",
    "#                 function_file = test_dict[\"prompt_id\"].split('/')[-1].split('.')[0]\n",
    "#                 test_classname = get_classname(test_dict[\"test_prompt\"].strip())\n",
    "#                 # \"```python\" and \"```\"\n",
    "#                 old_test, applied_heuristics[1] = fix1(old_test)\n",
    "#             elif model == \"CodeLlama\":\n",
    "#                 # \"```\" and \"```\"\n",
    "#                 old_test = test_dict[\"generated_text\"][-1][\"content\"]\n",
    "#                 function_file = test_dict[\"prompt_id\"].split('/')[-1].split('.')[0]\n",
    "#                 test_classname = get_classname(test_dict[\"test_prompt\"].strip())\n",
    "#                 old_test, applied_heuristics[1] = fix1(old_test)\n",
    "#                 old_test, applied_heuristics[1] = fix3(old_test)\n",
    "#             elif (model == \"Qwen\") or (model == \"CodeGemma\") or (model == \"DeepSeek\"):\n",
    "#                 old_test = test_dict[\"generated_text\"][-1][\"content\"]\n",
    "#                 # old_test = test_dict[\"generated_text\"]\n",
    "#                 function_file = test_dict[\"prompt_id\"].split('/')[-1].split('.')[0]\n",
    "#                 test_classname = get_classname(test_dict[\"test_prompt\"].strip())\n",
    "#                 # nothing / one \"```python\" and \"```\" / multiple \"```python\" and \"```\" / text after \"unittest.main()\"\n",
    "#                 if old_test.count(\"```python\") == 1:\n",
    "#                     # print(\"==1\")\n",
    "#                     old_test, applied_heuristics[1] = fix1(old_test)\n",
    "#                 elif old_test.count(\"```python\") > 1:\n",
    "#                     # print(\">1\")\n",
    "#                     old_test, applied_heuristics[1] = fix1(old_test)\n",
    "#                 elif old_test.count(\"unittest.main()\"):\n",
    "#                     old_test, applied_heuristics[1] = fix4(old_test)\n",
    "#             # print(function_file, test_classname)\n",
    "#             # print(new_test)\n",
    "#             filename = function_file+\"_test.py\"\n",
    "#             print(filename)\n",
    "#             # print(\"\\n===========\\n\")\n",
    "#             save_generated_code(filename, old_test, fix_folder[i], True)\n",
    "            \n",
    "#             # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests fixing (java)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def get_classname(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Gets the name of the CUT from the test prompt.\n",
    "    @param code: the test prompt or the original code (it assumes it starts with `// classname.java`)\n",
    "    @return: the classname of the CUT or the unit test to be generated\n",
    "    \"\"\"\n",
    "    return code.split(\"\\n\")[0][3:-5].strip()\n",
    "\n",
    "def save_generated_code(filename: str, code: str, output_folder: str, isGPT3=False) -> None:\n",
    "    # create the output folder if needed\n",
    "    if not os.path.exists(output_folder): os.makedirs(output_folder)\n",
    "\n",
    "    with open(os.path.join(output_folder, filename), \"w\") as gen_file:\n",
    "        if isGPT3:\n",
    "            gen_file.write(code)\n",
    "        else:\n",
    "            # gen_file.write(prompt[\"test_prompt\"] + \"\\n\" + response['choices'][0][\"text\"])\n",
    "            print(\"isGPT3 error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix1(code):\n",
    "    \"\"\"\n",
    "    delete \"```java\" at the begining, and \"```\" at the end ==> H2\n",
    "    \"\"\"\n",
    "    applied_heuristic = False\n",
    "    pattern = r\"[\\S\\s.]*?\\`\\`\\`java([\\S\\s.]*?)\\`\\`\\`[\\S\\s.]*?\"\n",
    "    good_code = re.findall(pattern, code, re.DOTALL)\n",
    "    code = []\n",
    "    if len(good_code) > 0:\n",
    "        # print(\"This is length: \" , len(good_code))\n",
    "        code.append(good_code[0])\n",
    "        for i in range(1, len(good_code)):\n",
    "            code.append(good_code[i])\n",
    "        applied_heuristic = True\n",
    "    return code, applied_heuristic\n",
    "\n",
    "\n",
    "def fix2(code, test_classname, function_file):\n",
    "    \"\"\"\n",
    "    replaces the package name with the function file name ==> H4\n",
    "    adds the package name if it is missing (or remove it, if it is not needed) ==> H5\n",
    "    \"\"\"\n",
    "    applied_heuristic_h4, applied_heuristic_h5 = False, False\n",
    "\n",
    "    # search only in the beginning of the file (before the test class)\n",
    "    if not re.search(f\"import {test_classname}\", code, re.IGNORECASE):\n",
    "        print(function_file)\n",
    "        return code, applied_heuristic_h4, applied_heuristic_h5\n",
    "    m = re.search(f\"from {test_classname} \", code[:code.index(f\"import {test_classname}\")], re.IGNORECASE)\n",
    "    # print(test_classname, code[:code.index(f\"import {test_classname}\")])\n",
    "    # print(m)\n",
    "    \n",
    "    missing = True\n",
    "    if m:\n",
    "        missing = False\n",
    "        code = code[:m.start()] + f\"from {function_file} \" + code[m.end():]\n",
    "    \n",
    "    # test should be in a package, but package declaration is missing\n",
    "    # thus, apply H5 here\n",
    "    # print(code[:m.start()])\n",
    "    # print(test_classname, missing)\n",
    "    if test_classname and missing:\n",
    "        code = f\"from {function_file} import {test_classname}\\n\" + code\n",
    "        applied_heuristic_h5 = True\n",
    "    # if not test_classname and not missing:\n",
    "    #     # remove the package declaration\n",
    "    #     code = code[:m.start()] + code[m.end():]\n",
    "    #     applied_heuristic_h5 = True\n",
    "    return code, applied_heuristic_h4, applied_heuristic_h5\n",
    "\n",
    "def fix3(code):\n",
    "    \"\"\"\n",
    "    delete \"```\" at the begining, and \"```\" at the end\n",
    "    \"\"\"\n",
    "    applied_heuristic = False\n",
    "    pattern = r\"[\\S\\s.]*?\\`\\`\\`([\\S\\s.]*?)\\`\\`\\`[\\S\\s.]*?\"\n",
    "    good_code = re.findall(pattern, code, re.DOTALL)\n",
    "    code = []\n",
    "    if len(good_code) > 0:\n",
    "        # print(\"This is length: \" , len(good_code))\n",
    "        code.append(good_code[0])\n",
    "        for i in range(1, len(good_code)):\n",
    "            code.append(good_code[i])\n",
    "        applied_heuristic = True\n",
    "    return code, applied_heuristic\n",
    "\n",
    "\n",
    "def fix4(code):\n",
    "    \"\"\"\n",
    "    delete \"```java\" at the begining, and \"```\" at the end ==> H2\n",
    "    \"\"\"\n",
    "    parts = re.split(r'(package [^;]+;)', code)\n",
    "    result = [parts[i] + parts[i + 1] for i in range(1, len(parts), 2)]\n",
    "    return result\n",
    "    return code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPT3.5 fix1\n",
    "# # CodeLlama fix3 + formatter\n",
    "# import pandas as pd\n",
    "\n",
    "# model = \"O1\"\n",
    "# fix_folder = [f\"./generated_tests/{model}_Data/ProjectTestjava_output/original_fix\"]\n",
    "# models = [model]\n",
    "# applied_heuristics = [False for _ in range(0, 7)]\n",
    "\n",
    "# for i in range(len(models)):\n",
    "#     model = models[i]\n",
    "#     for dataset in [\"ProjectTest\"]:\n",
    "#         tests_output = json.load(open(f'./generated_tests/{model}_Data/{dataset}java_output/original_output_-1.json'))\n",
    "#         for test_dict in tests_output:\n",
    "#             if model == \"O1\":\n",
    "#                 old_test = test_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "#                 function_file = test_dict[\"prompt_id\"].split('/')[-1].split('.')[0]\n",
    "#                 test_classname = get_classname(test_dict[\"test_prompt\"].strip())\n",
    "#                 old_test = fix4(old_test)\n",
    "#             if (model == \"GPT3.5\") or (model == \"GPT4\"):\n",
    "#                 # \"```java\" and \"```\"\n",
    "#                 old_test = test_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "#                 function_file = test_dict[\"prompt_id\"].split('/')[-1].split('.')[0]\n",
    "#                 test_classname = get_classname(test_dict[\"test_prompt\"].strip())\n",
    "#                 old_test, applied_heuristics[1] = fix1(old_test)\n",
    "#             elif (model == \"Gemini\") or (model == \"Claude\"):\n",
    "#                 # \"```java\" and \"```\"\n",
    "#                 old_test = test_dict[\"generated_text\"]\n",
    "#                 function_file = test_dict[\"prompt_id\"].split('/')[-1].split('.')[0]\n",
    "#                 test_classname = get_classname(test_dict[\"test_prompt\"].strip())\n",
    "#                 old_test, applied_heuristics[1] = fix1(old_test)\n",
    "#             elif model == \"CodeLlama\" or model == \"DeepSeek\" or (model == \"CodeGemma\") or (model == \"Qwen\"):\n",
    "#                 # \"```java\" and \"```\"\n",
    "#                 old_test = test_dict[\"generated_text\"][-1][\"content\"]\n",
    "#                 function_file = test_dict[\"prompt_id\"].split('/')[-1].split('.')[0]\n",
    "#                 test_classname = get_classname(test_dict[\"test_prompt\"].strip())\n",
    "#                 if \"```java\" in old_test:\n",
    "#                     old_test, applied_heuristics[1] = fix1(old_test)\n",
    "#                 else:\n",
    "#                     old_test, applied_heuristics[1] = fix3(old_test)\n",
    "#             for c in range(len(old_test)):\n",
    "#                 code = old_test[c]\n",
    "#                 filename = function_file+f\"{c}.java\"\n",
    "#                 save_generated_code(filename, code, fix_folder[i], True)\n",
    "#             # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests fixing (js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "def get_classname(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Gets the name of the CUT from the test prompt.\n",
    "    @param code: the test prompt or the original code (it assumes it starts with `// classname.java`)\n",
    "    @return: the classname of the CUT or the unit test to be generated\n",
    "    \"\"\"\n",
    "    return code.split(\"\\n\")[0][3:-8].strip()\n",
    "\n",
    "def save_generated_code(filename: str, code: str, output_folder: str, isGPT3=False) -> None:\n",
    "    # create the output folder if needed\n",
    "    if not os.path.exists(output_folder): os.makedirs(output_folder)\n",
    "\n",
    "    with open(os.path.join(output_folder, filename), \"w\") as gen_file:\n",
    "        if isGPT3:\n",
    "            gen_file.write(code)\n",
    "        else:\n",
    "            # gen_file.write(prompt[\"test_prompt\"] + \"\\n\" + response['choices'][0][\"text\"])\n",
    "            print(\"isGPT3 error\")\n",
    "\n",
    "\n",
    "def fix1(code):\n",
    "    \"\"\"\n",
    "    delete \"```javascript\" at the begining, and \"```\" at the end\n",
    "    \"\"\"\n",
    "    applied_heuristic = False\n",
    "    pattern = r\"[\\S\\s.]*?\\`\\`\\`javascript([\\S\\s.]*?)\\`\\`\\`[\\S\\s.]*?\"\n",
    "    good_code = re.findall(pattern, code, re.DOTALL)\n",
    "    code = []\n",
    "    if len(good_code) > 0:\n",
    "        # print(\"This is length: \" , len(good_code))\n",
    "        code.append(good_code[0])\n",
    "        for i in range(1, len(good_code)):\n",
    "            code.append(good_code[i])\n",
    "        applied_heuristic = True\n",
    "    return code, applied_heuristic\n",
    "\n",
    "def fix2(code, test_classname, function_file):\n",
    "    \"\"\"\n",
    "    replaces the package name with the function file name \n",
    "    adds the package name if it is missing (or remove it, if it is not needed) ==> H5\n",
    "    \"\"\"\n",
    "    applied_heuristic_h4, applied_heuristic_h5 = False, False\n",
    "\n",
    "    # search only in the beginning of the file (before the test class)\n",
    "    if not re.search(f\"import {test_classname}\", code, re.IGNORECASE):\n",
    "        print(function_file)\n",
    "        return code, applied_heuristic_h4, applied_heuristic_h5\n",
    "    m = re.search(f\"from {test_classname} \", code[:code.index(f\"import {test_classname}\")], re.IGNORECASE)\n",
    "    # print(test_classname, code[:code.index(f\"import {test_classname}\")])\n",
    "    # print(m)\n",
    "    \n",
    "    missing = True\n",
    "    if m:\n",
    "        missing = False\n",
    "        code = code[:m.start()] + f\"from {function_file} \" + code[m.end():]\n",
    "    \n",
    "    # test should be in a package, but package declaration is missing\n",
    "    # thus, apply H5 here\n",
    "    # print(code[:m.start()])\n",
    "    # print(test_classname, missing)\n",
    "    if test_classname and missing:\n",
    "        code = f\"from {function_file} import {test_classname}\\n\" + code\n",
    "        applied_heuristic_h5 = True\n",
    "    # if not test_classname and not missing:\n",
    "    #     # remove the package declaration\n",
    "    #     code = code[:m.start()] + code[m.end():]\n",
    "    #     applied_heuristic_h5 = True\n",
    "    return code, applied_heuristic_h4, applied_heuristic_h5\n",
    "\n",
    "def fix3(code):\n",
    "    \"\"\"\n",
    "    delete \"```\" at the begining, and \"```\" at the end\n",
    "    \"\"\"\n",
    "    applied_heuristic = False\n",
    "    pattern = r\"[\\S\\s.]*?\\`\\`\\`([\\S\\s.]*?)\\`\\`\\`[\\S\\s.]*?\"\n",
    "    good_code = re.findall(pattern, code, re.DOTALL)\n",
    "    code = []\n",
    "    if len(good_code) > 0:\n",
    "        # print(\"This is length: \" , len(good_code))\n",
    "        code.append(good_code[0])\n",
    "        for i in range(1, len(good_code)):\n",
    "            code.append(good_code[i])\n",
    "        applied_heuristic = True\n",
    "    return code, applied_heuristic\n",
    "\n",
    "\n",
    "def fix4(data):\n",
    "    # Define all possible separators\n",
    "    separators = [\n",
    "        r'-{80}\\n(.*?)\\n-{80}',  # Format: 80 dashes\n",
    "        r'={80}\\n(.*?)\\n={80}',  # Format: 80 equal signs\n",
    "        r'\\*{86}\\n/\\* FILE: (.*?) \\*/\\n\\*{86}',  # Format: 86 asterisks + FILE:\n",
    "        r'/{78}\\n// File: (.*?)\\n(?:.|\\n)*?/{78}',  # Format: 78 slashes + metadata\n",
    "        r'// {77}\\n(.*?)\\n// {77}'  # Format: 77 slashes\n",
    "    ]\n",
    "\n",
    "    # Detect which separator exists in the data\n",
    "    selected_separator = None\n",
    "    for sep in separators:\n",
    "        if re.search(sep, data):\n",
    "            selected_separator = sep\n",
    "            break\n",
    "\n",
    "    # If a separator is found, split data accordingly\n",
    "    if selected_separator:\n",
    "        split_pattern = re.split(selected_separator + r'\\n', data)[1:]\n",
    "        file_data = [split_pattern[i + 1] for i in range(0, len(split_pattern) - 1, 2)]\n",
    "    else:\n",
    "        # No separator found, store entire data in the list\n",
    "        file_data = [data]\n",
    "    return file_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPT3.5 fix1\n",
    "# # CodeLlama fix3 + formatter\n",
    "\n",
    "# model = \"O1\"\n",
    "# fix_folder = [f\"./generated_tests/{model}_Data/ProjectTestjs_output/original_fix\"]\n",
    "# models = [model]\n",
    "# applied_heuristics = [False for _ in range(0, 7)]\n",
    "\n",
    "# for i in range(len(models)):\n",
    "#     model = models[i]\n",
    "#     for dataset in [\"ProjectTest\"]:\n",
    "#         tests_output = json.load(open(f'./generated_tests/{model}_Data/{dataset}js_output/original_output_-1.json'))\n",
    "#         for test_dict in tests_output:\n",
    "#             if model == \"O1\":\n",
    "#                 old_test = test_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "#             else:\n",
    "#                 old_test = test_dict[\"generated_text\"]\n",
    "#             function_file = test_dict[\"prompt_id\"].split('/')[-1].split('.')[0]\n",
    "#             print(function_file)\n",
    "#             # if function_file == \"spherical\":\n",
    "#             #     continue\n",
    "#             if model == \"CodeLlama\" or model == \"CodeGemma\":\n",
    "#                 test_classname = get_classname(test_dict[\"test_prompt\"].strip())\n",
    "#                 if \"```javascript\" in old_test:\n",
    "#                     old_test, applied_heuristics[1] = fix1(old_test)\n",
    "#                 else:\n",
    "#                     old_test, applied_heuristics[1] = fix3(old_test)\n",
    "#             elif model == \"O1\":\n",
    "#                 test_classname = get_classname(test_dict[\"test_prompt\"].strip())\n",
    "#                 old_test = fix4(old_test)\n",
    "#             else:\n",
    "#                 test_classname = get_classname(test_dict[\"test_prompt\"].strip())\n",
    "#                 old_test, applied_heuristics[1] = fix1(old_test)\n",
    "#                 # new_test, applied_heuristics[3], applied_heuristics[4] = fix2(old_test, test_classname, function_file)\n",
    "            \n",
    "#             print(len(old_test))\n",
    "#             for c in range(len(old_test)):\n",
    "#                 code = old_test[c]\n",
    "#                 # print(code)\n",
    "#                 filename = function_file+f\"{c}.test.js\"\n",
    "#                 save_generated_code(filename, code, fix_folder[i], True)\n",
    "            \n",
    "#             # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProjectTest Pytest & javatest Move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python\n",
    "move to pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# model = \"O1\"\n",
    "# original_code_folder = \"./dataset/Python\"\n",
    "# generated_test_folders = [f\"./generated_tests/{model}_Data/ProjectTestPy_output/original_fix\"]\n",
    "# output_folders = [f\"./pytest/{model}/ProjectTest/Python/original_fix\"]\n",
    "\n",
    "# for i in range(len(generated_test_folders)):\n",
    "#     # Iterate over all entries in the parent directory\n",
    "#     for entry in os.listdir(original_code_folder):\n",
    "#         # Create full path\n",
    "#         full_path = os.path.join(original_code_folder, entry)\n",
    "#         # Check if it's a directory\n",
    "#         if os.path.isdir(full_path):\n",
    "#             # print(full_path)\n",
    "#             shutil.copytree(full_path, os.path.join(output_folders[i], entry))\n",
    "#             test_file = os.path.join(generated_test_folders[i], entry+\"_test.py\")\n",
    "#             # print(test_file)\n",
    "#             if os.path.isfile(test_file):\n",
    "#                 print(entry)\n",
    "#                 shutil.copy2(test_file, os.path.join(output_folders[i], entry))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Java\n",
    "move to javatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# from lxml import etree\n",
    "# from pathlib import Path\n",
    "# parser = etree.XMLParser(remove_blank_text=True)\n",
    "\n",
    "# def remove_namespace(doc):\n",
    "#     for elem in doc.getiterator():\n",
    "#         if 'ns0:' in elem.tag:\n",
    "#             elem.tag = elem.tag.replace('ns0:', '')\n",
    "#     return doc\n",
    "\n",
    "# def copy_files(src_folder, dest_folder):\n",
    "#     # Ensure source folder exists\n",
    "#     if not os.path.exists(src_folder):\n",
    "#         print(f\"Source folder '{src_folder}' does not exist.\")\n",
    "#         return\n",
    "    \n",
    "#     # Ensure destination folder exists\n",
    "#     if not os.path.exists(dest_folder):\n",
    "#         print(f\"Destination folder '{dest_folder}' does not exist.\")\n",
    "#         return\n",
    "    \n",
    "#     shutil.copytree(src_folder, dest_folder, dirs_exist_ok=True)\n",
    "    \n",
    "# model = \"O1\"\n",
    "# original_code_folder = \"./dataset/JAVA\"\n",
    "# generated_test_folders = [f\"./generated_tests/{model}_Data/ProjectTestjava_output/original_fix\"]\n",
    "# mvn_path = \"./javatest/test\"\n",
    "# poms_path = \"./javatest/poms\"\n",
    "\n",
    "# for i in range(len(generated_test_folders)):\n",
    "#     # Iterate over all entries in the parent directory\n",
    "#     for entry in os.listdir(original_code_folder):\n",
    "#         # Create full path\n",
    "#         full_path = os.path.join(original_code_folder, entry)\n",
    "#         print(full_path)\n",
    "#         # Check if it's a directory\n",
    "#         if os.path.isdir(full_path):\n",
    "#             # copy mvn projects from test to gpt35_{entry}\n",
    "#             new_mvn_path = f\"./javatest/{model}/abcd_without/{model.lower()}_{entry}\"\n",
    "#             shutil.copytree(mvn_path, new_mvn_path)\n",
    "#             new_pom = os.path.join(poms_path, f\"{entry}.xml\")\n",
    "#             target_pom_path = os.path.join(new_mvn_path, f\"pom.xml\")\n",
    "#             if os.path.isfile(new_pom):\n",
    "#                 shutil.copy(new_pom, target_pom_path)\n",
    "\n",
    "#             # update main_path and test_path\n",
    "#             main_path = os.path.join(new_mvn_path, f\"src/main/java/projecttest/{entry}\")\n",
    "#             test_path = os.path.join(new_mvn_path, f\"src/test/java/projecttest/{entry}\")\n",
    "#             os.makedirs(main_path, exist_ok=True)\n",
    "#             os.makedirs(test_path, exist_ok=True)\n",
    "#             # move files in full_path to main_path\n",
    "#             copy_files(full_path, main_path)\n",
    "#             # move {enrty}Test.java to test_path\n",
    "#             for test_file in list(Path(generated_test_folders[i]).glob(f\"{entry}*\")):\n",
    "#                 shutil.copy2(test_file, test_path)\n",
    "#             # delete App.java and AppTest.java\n",
    "#             os.remove(os.path.join(os.path.join(new_mvn_path, f\"src/main/java/projecttest\"), \"App.java\"))\n",
    "#             os.remove(os.path.join(os.path.join(new_mvn_path, f\"src/test/java/projecttest\"), \"AppTest.java\"))\n",
    "#         # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### js\n",
    "move to js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "# model = \"O1\"\n",
    "# original_code_folder = \"./dataset/JS\"\n",
    "# generated_test_folders = [f\"./generated_tests/{model}_Data/ProjectTestjs_output/original_fix\"]\n",
    "# output_folders = [f\"./jstest/{model}/ProjectTest/JS/original_fix\"]\n",
    "\n",
    "# for i in range(len(generated_test_folders)):\n",
    "#     # Iterate over all entries in the parent directory\n",
    "#     for entry in os.listdir(original_code_folder):\n",
    "#         print(entry)\n",
    "#         # Create full path\n",
    "#         full_path = os.path.join(original_code_folder, entry)\n",
    "#         # Check if it's a directory\n",
    "#         if os.path.isdir(full_path):\n",
    "#             shutil.copytree(full_path, os.path.join(output_folders[i], entry))\n",
    "#             for test_file in list(Path(generated_test_folders[i]).glob(f\"{entry}*\")):\n",
    "#                 print(test_file)\n",
    "#                 if os.path.isfile(test_file):\n",
    "#                     print(entry)\n",
    "#                     shutil.copy2(test_file, os.path.join(output_folders[i], entry))\n",
    "#                     shutil.copy2(\"./jstest/package.json\", os.path.join(output_folders[i], entry))\n",
    "#                     shutil.copy2(\"./jstest/.babelrc\", os.path.join(output_folders[i], entry))\n",
    "#         # break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OOD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
